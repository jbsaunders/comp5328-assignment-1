{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IrXtNd8l-9H"
      },
      "source": [
        "## COMP5328 - Advanced Machine Learning\n",
        "## Assignment 1: Non-negative Matrix Factorization\n",
        "----------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZF6lvwjl-9H"
      },
      "source": [
        "**(Semester 2, 2025)**\n",
        "\n",
        "In this ipython notebook, we provide some example code for assignment1.\n",
        "+ Load Data.\n",
        "    - ORL dataset.\n",
        "    - Extended YaleB dataset.\n",
        "    - AR dataset (**optional**).\n",
        "+ Perform Evaluation.\n",
        "   - Relative Reconstruction Errors.\n",
        "   - Accuracy, NMI (**optional**).\n",
        "\n",
        "Lecturer: Tongliang Liu.\n",
        "\n",
        "**Note: All datasets can be used only for this assignment and you are not allowed to distribute these datasets. If you want to use AR dataset, you need to apply it by yourself (we do not provide AR dataset due to the problem of license, please find more details in http://www2.ece.ohio-state.edu/~aleix/ARdatabase.html).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYzWuiytl-9I"
      },
      "source": [
        "## 1. Load Dataset\n",
        "\n",
        "### 1.0 Data Folder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your dataset zip stored in Drive\n",
        "zip_path = \"/content/drive/MyDrive/comp4328/a1/data.zip\"\n",
        "\n",
        "# Unzip into Colab local filesystem\n",
        "!unzip -q \"$zip_path\" -d /content/data\n",
        "\n",
        "# Inspect structure\n",
        "!ls -R /content/data | head -20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxEr9ihznSqa",
        "outputId": "8b9fd2c9-b2f9-45f4-94aa-d0d473b7e140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "replace /content/data/data/CroppedYaleB/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: /content/data:\n",
            "data\n",
            "__MACOSX\n",
            "\n",
            "/content/data/data:\n",
            "CroppedYaleB\n",
            "ORL\n",
            "\n",
            "/content/data/data/CroppedYaleB:\n",
            "yaleB01\n",
            "yaleB02\n",
            "yaleB03\n",
            "yaleB04\n",
            "yaleB05\n",
            "yaleB06\n",
            "yaleB07\n",
            "yaleB08\n",
            "yaleB09\n",
            "yaleB10\n",
            "yaleB11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRp8CtkNl-9I",
        "outputId": "589fff04-9db7-4886-f6c9-02224ada0792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "drwx------ 4 root root 4096 Aug 25  2018 data\n",
            "drwxrwxr-x 3 root root 4096 Aug 25  2018 __MACOSX\n"
          ]
        }
      ],
      "source": [
        "# The structure of data folder.\n",
        "!ls -l data"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "xxXQvUPpl-9I"
      },
      "source": [
        "# Tree structure of data folder.\n",
        "├── CroppedAR\n",
        "    ├── M-001-01.bmp\n",
        "    ├── M-001-01.txt\n",
        "    ├── M-001-02.bmp\n",
        "    ├── M-001-02.txt\n",
        "    ├── ...\n",
        "├── CroppedYaleB\n",
        "│   ├── yaleB01\n",
        "│   ├── yaleB02\n",
        "│   ...\n",
        "│   ├── yaleB38\n",
        "│   └── yaleB39\n",
        "└── ORL\n",
        "    ├── s1\n",
        "    ├── s2\n",
        "    ├── s3\n",
        "    ├── ...\n",
        "    ├── s40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Isgiu1El-9I"
      },
      "source": [
        "### 1.1 Load ORL Dataset and Extended YaleB Dataset.\n",
        "+ ORL dataset contains ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement). The size of each image is 92x112 pixels, with 256 grey levels per pixel. To further reduce the computation complexity, you can resize all images to 30x37 pixels.\n",
        "\n",
        "+ Extended YaleB dataset contains 2414 images of 38 human subjects under 9 poses and 64 illumination conditions. All images are manually aligned, cropped, and then resized to 168x192 pixels. To further reduce the computation complexity, you can resize all images to 42x48 pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCUuJZxml-9J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def load_data(root='/content/data/data/CroppedYaleB', reduce=3, normalization=\"per_image\", eps=1e-12):\n",
        "    \"\"\"\n",
        "    Load ORL (or Extended YaleB) dataset to numpy array.\n",
        "\n",
        "    Args:\n",
        "        root: path to dataset.\n",
        "        reduce: scale factor for zooming out images.\n",
        "\n",
        "    \"\"\"\n",
        "    images, labels = [], []\n",
        "    height, width = 0, 0\n",
        "\n",
        "    for i, person in enumerate(sorted(os.listdir(root))):\n",
        "\n",
        "        if not os.path.isdir(os.path.join(root, person)):\n",
        "            continue\n",
        "\n",
        "        for fname in os.listdir(os.path.join(root, person)):\n",
        "\n",
        "            # Remove background images in Extended YaleB dataset.\n",
        "            if fname.endswith('Ambient.pgm'):\n",
        "                continue\n",
        "\n",
        "            if not fname.endswith('.pgm'):\n",
        "                continue\n",
        "\n",
        "            # load image.\n",
        "            img = Image.open(os.path.join(root, person, fname))\n",
        "            img = img.convert('L') # grey image.\n",
        "\n",
        "\n",
        "            # reduce computation complexity.\n",
        "            img = img.resize([s//reduce for s in img.size])\n",
        "\n",
        "            # save the height/width after resizing\n",
        "            if (height == 0 or width == 0):\n",
        "              height = img.size[1]\n",
        "              width = img.size[0]\n",
        "\n",
        "            img = np.asarray(img, dtype=np.float32)\n",
        "\n",
        "            # normalzation per image\n",
        "            if normalization == \"per_image\":\n",
        "              img = (img - img.min()) / (img.max() - img.min() + eps)\n",
        "\n",
        "            img = img.reshape((-1,1))\n",
        "\n",
        "            # collect data and label.\n",
        "            images.append(img)\n",
        "            labels.append(i)\n",
        "\n",
        "    # concate all images and labels.\n",
        "    images = np.concatenate(images, axis=1)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # normalize globally\n",
        "    if normalization == \"global\":\n",
        "      images = images.astype(np.float32)\n",
        "      images = images / 255.0 # normalizing them\n",
        "\n",
        "\n",
        "    return images, labels, height, width\n",
        "\n",
        "# salt and pepper noise\n",
        "def add_sp_noise(V_hat, p=0, r=0, rng=None):\n",
        "\n",
        "  if rng is None:\n",
        "    rng = np.random.default_rng()\n",
        "\n",
        "  m, n = V_hat.shape # n images, each has m pixels in a flat vector\n",
        "\n",
        "  V_noise = V_hat.copy()\n",
        "\n",
        "  for i in range(n): #iterate through each image\n",
        "    for j in range(m): #iterate through each pixel\n",
        "      if rng.random() < p: #we modify the pixel\n",
        "        if rng.random() < r:\n",
        "          V_noise[j, i] = 1.0 # turn the pixel white\n",
        "        else:\n",
        "          V_noise[j, i] = 0.0 # turn the pixel black\n",
        "\n",
        "  return V_noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T_-fgIOl-9J"
      },
      "source": [
        "---------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwYcD7nsl-9J"
      },
      "source": [
        "## 2. Evaluation Metrics\n",
        "\n",
        "\n",
        "### 2.1 Relative Reconstruction Errors (RRE)\n",
        "\n",
        "To compare the robustness of different NMF algorithms, you can use the ```relative reconstruction errors```. Let $V$ denote the contaminated dataset (by adding noise), and $\\hat{V}$\n",
        " denote the clean dataset. Let $W$ and $H$ denote the factorization results on $V$, the ``relative reconstruction errors`` then can be defined as follows:\n",
        " \\begin{equation}\n",
        "    RRE = \\frac{ \\| \\hat{V} - WH \\|_F }{ \\| \\hat{V} \\|_F}.\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining NMF Funtions\n",
        "\n",
        "# FSE method\n",
        "def frobenius_squared_error(V, W, H):\n",
        "    WH = W @ H\n",
        "    return np.sum((V - WH) ** 2)\n",
        "\n",
        "def rre_fse(V_hat, W, H, eps=1e-12): # V_hat is the clean matrix (pre-noise)\n",
        "  WH = W @ H\n",
        "  FE = np.linalg.norm( V_hat - WH, ord='fro')\n",
        "  denom = np.linalg.norm(V_hat, ord='fro')\n",
        "  RRE = FE / (denom + eps)\n",
        "  return RRE\n",
        "\n",
        "def fse_mur(V, W, H, max_iterations, eps=1e-12, verbosity=1):\n",
        "  if verbosity >= 1:\n",
        "    print(\"Starting FSE MUR training...\")\n",
        "  errors = []\n",
        "  prev = None\n",
        "\n",
        "  iterations_done = 0\n",
        "\n",
        "  for it in range(max_iterations):\n",
        "      numerator_H = W.T @ V\n",
        "      denominator_H = (W.T @ W @ H)\n",
        "\n",
        "      H = H * numerator_H / (denominator_H + eps)\n",
        "\n",
        "      numerator_W = V @ H.T\n",
        "      denominator_W = (W @ H @ H.T)\n",
        "\n",
        "      W = W * numerator_W / (denominator_W + eps)\n",
        "\n",
        "      training_error = frobenius_squared_error(V, W, H)\n",
        "      errors.append(training_error)\n",
        "      iterations_done += 1\n",
        "\n",
        "      if (iterations_done%100) == 0:\n",
        "        if verbosity >= 1:\n",
        "          print(f\"Completed {iterations_done} iterations out of {max_iterations}\")\n",
        "        if verbosity >= 2:\n",
        "          print(f\"\\t Training error = {training_error:.2f}\")\n",
        "\n",
        "      # check for early stopping\n",
        "      if prev is None:\n",
        "        prev = training_error\n",
        "        continue\n",
        "\n",
        "      if prev is not None:\n",
        "        rel = abs(training_error - prev) / (abs(prev) + eps)\n",
        "        if rel < config[\"tol\"]: # if the curve has flattened too much or is going up\n",
        "          if verbosity >= 1:\n",
        "            print(\"Early stopping at iteration: \", it) # stop\n",
        "          break\n",
        "        prev = training_error\n",
        "\n",
        "  if verbosity >= 1:\n",
        "    print(f\"Completed {iterations_done} iterations\")\n",
        "\n",
        "  return W, H, errors\n",
        "\n",
        "# L2,1 Norm method\n",
        "\n",
        "def l21_norm(V, W, H): # finds the L_2,1 Norm objective function result\n",
        "    R = V - W @ H\n",
        "    return np.linalg.norm(R, axis=0).sum(0) #axis =0 means we go column by column\n",
        "\n",
        "def compute_u(V, WH, eps=1e-12): # computes u the vector instead of matrix U. Faster calculations\n",
        "    R = V - WH\n",
        "    col_norms = np.linalg.norm(R, axis=0) # gets a vector of all the norms of the columns of R\n",
        "    u = 1.0 / np.maximum(col_norms, eps) # inverts them\n",
        "    return u\n",
        "\n",
        "def rre_l21_norm(V_hat, W, H, eps=1e-12):\n",
        "  R = V_hat - W @ H\n",
        "  nom = np.linalg.norm(R, axis=0).sum(0)\n",
        "  denom = np.linalg.norm(V_hat, axis=0).sum(0)\n",
        "  RRE = nom / (denom + eps)\n",
        "  return RRE\n",
        "\n",
        "def l21_norm_mur(V, W, H, max_iterations, eps=1e-12, delta=1e-12, verbosity=1): # does the H update and W update steps for L21 NMF\n",
        "  if verbosity >= 1:\n",
        "    print(\"Staring L2,1 Norm NMF MUR training...\")\n",
        "  errors = []\n",
        "  prev = None\n",
        "  iterations_done = 0\n",
        "\n",
        "  for it in range(max_iterations):\n",
        "      # precompute some variables to save runtime\n",
        "      WH = W @ H\n",
        "      u = compute_u(V, WH, eps=eps) # finds u but as a vector, not full diagonal matrix U\n",
        "      V_u = V * u\n",
        "\n",
        "      numerator_H = W.T @ (V_u)\n",
        "      denominator_H = W.T @ (WH * u) + delta # includes delta to avoid division by zero\n",
        "\n",
        "      H *= numerator_H / denominator_H # updates H\n",
        "      H = np.maximum(H, 0) # clips it to keep it non-negative\n",
        "\n",
        "      WH = W@H # recompute now that we've updated H\n",
        "\n",
        "      numerator_W = (V_u) @ H.T\n",
        "      denominator_W = (WH * u) @ H.T + delta\n",
        "\n",
        "      W *= numerator_W / denominator_W # updates W\n",
        "      W = np.maximum(W, 0) # clips it to keep it non-negative\n",
        "\n",
        "      training_error = l21_norm(V, W, H)\n",
        "      errors.append(training_error) # tracks the objective function value at each update step\n",
        "      iterations_done += 1\n",
        "\n",
        "      if (iterations_done%100) == 0:\n",
        "        if verbosity >= 1:\n",
        "          print(f\"Completed {iterations_done} iterations out of {max_iterations}\")\n",
        "        if verbosity >= 2:\n",
        "          print(f\"\\tTraining error = {training_error:.2f}\")\n",
        "\n",
        "      # check for early stopping\n",
        "      if prev is None:\n",
        "        prev = training_error\n",
        "        continue\n",
        "\n",
        "      if prev is not None:\n",
        "        rel = abs(training_error - prev) / (abs(prev) + eps)\n",
        "        if rel < config[\"tol\"]: # if the curve has flattened too much or is going up\n",
        "          if verbosity >= 1:\n",
        "            print(\"Early stopping at iteration: \", it) # stop\n",
        "          break\n",
        "        prev = training_error\n",
        "\n",
        "  if verbosity >= 1:\n",
        "    print(f\"Completed {iterations_done} iterations\")\n",
        "  return W, H, errors\n",
        "\n"
      ],
      "metadata": {
        "id": "9glxNYqnpCWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly select 90%\n",
        "def make_stratified_subset(V, Y, V_hat, frac=0.9, seed=0):\n",
        "  rng = np.random.default_rng(seed)\n",
        "  labels = np.unique(Y)\n",
        "  idx_trimmed = []\n",
        "  # print(labels)\n",
        "  for cls in labels:\n",
        "    cls_idx = np.where(Y == cls)[0]\n",
        "    amount_to_keep = int(frac * len(cls_idx))\n",
        "    chosen = rng.choice(cls_idx, size=amount_to_keep, replace=False)\n",
        "    idx_trimmed.extend(chosen)\n",
        "  idx_trimmed = np.array(idx_trimmed)\n",
        "  V_trimmed = V[:, idx_trimmed]\n",
        "  Y_trimmed = Y[idx_trimmed]\n",
        "  V_hat_trimmed = V_hat[:, idx_trimmed]\n",
        "  return V_trimmed, Y_trimmed, V_hat_trimmed\n",
        "\n",
        "V_trimmed, Y_trimmed, V_hat_trimmed = make_stratified_subset(V, Y_hat, V_hat)\n"
      ],
      "metadata": {
        "id": "7382CAUnpb6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_GIK5ngl-9J"
      },
      "source": [
        "### 2.2 Evaluate Clustering Performance\n",
        "\n",
        "1. Accuracy.\n",
        "    \n",
        "    $$ Acc(Y, Y_{pred}) = \\frac{1}{n}\\sum\\limits_{i=1}^n 1\\{Y_{pred}(i) == Y(i)\\}$$\n",
        "        \n",
        "2. Normalized Mutual Information (NMI).\n",
        "\n",
        "    $$ NMI(Y, Y_{pred}) = \\frac{2 * I(Y, Y_{pred})}{H(Y) + H(Y_{pred})} $$\n",
        "    \n",
        "   where $ I(\\cdot,\\cdot) $ is mutual information and $ H(\\cdot) $ is entropy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fULYSeVUl-9J",
        "outputId": "7564606c-5744-4024-879d-a9f4fab589be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Evaluate Acc and NMI ...\n",
            "Acc(NMI) = 0.6139 (0.7815)\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import normalized_mutual_info_score\n",
        "\n",
        "def assign_cluster_label(X, Y, verbosity=1):\n",
        "    if verbosity >= 2:\n",
        "      print(\"Num of classes = \", len(set(Y)))\n",
        "    kmeans = KMeans(n_clusters=len(set(Y))).fit(X)\n",
        "    Y_pred = np.zeros(Y.shape)\n",
        "    for i in set(kmeans.labels_):\n",
        "        ind = kmeans.labels_ == i\n",
        "        Y_pred[ind] = Counter(Y[ind]).most_common(1)[0][0] # assign label.\n",
        "    return Y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# running the whole thing in one function\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def run_config(config, verbosity=1):\n",
        "  rng = np.random.default_rng(config[\"seed\"])\n",
        "  eps = config[\"epsilon\"]\n",
        "\n",
        "  for key, value in config.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "  print()\n",
        "\n",
        "  # Load dataset.\n",
        "  if verbosity >= 1:\n",
        "    print(f\"Loading {config['dataset']} dataset ...\")\n",
        "  if config[\"dataset\"] == \"ORL\":\n",
        "    V_hat, Y_hat, h, w = load_data(root='/content/data/data/ORL', reduce=config[\"reduce_ORL\"], normalization=config[\"normalization\"])\n",
        "  elif config[\"dataset\"] == \"YALE\":\n",
        "    V_hat, Y_hat, h, w = load_data(root='/content/data/data/CroppedYaleB', reduce=config[\"reduce_YALE\"], normalization=config[\"normalization\"])\n",
        "  else:\n",
        "    raise ValueError(f\"Unkown dataset in config: {config['dataset']}\")\n",
        "\n",
        "  if verbosity >= 2:\n",
        "    print('V_hat.shape={}, Y_hat.shape={}'.format(V_hat.shape, Y_hat.shape))\n",
        "    print(\"Image count = \", V_hat.shape[1])\n",
        "    print(\"Dimensions after reduction:\")\n",
        "    print(\"\\theight = \", h)\n",
        "    print(\"\\twidth = \", w)\n",
        "    print(\"Flattened image vector length = \", V_hat.shape[0])\n",
        "    print(\"Number of unique labels in Y = \", len(set(Y_hat)))\n",
        "\n",
        "\n",
        "\n",
        "  # check if h*w = pixel count after reduction\n",
        "  if (h*w != V_hat.shape[0]):\n",
        "    raise ValueError(f\"h*w =/= pixel count\\nhw = {h*w}\\nV_hat.shape[0] = {V_hat.shape[0]}\")\n",
        "    exit(1)\n",
        "\n",
        "  # Add Noise - the Salt and Pepper way\n",
        "  V = add_sp_noise(V_hat, config[\"noise_p\"], config[\"noise_r\"])\n",
        "\n",
        "  max_runs = 5\n",
        "\n",
        "  rre_scores = []\n",
        "  acc_scores = []\n",
        "  nmi_scores = []\n",
        "\n",
        "  for i in range(max_runs):\n",
        "    if verbosity >= 1:\n",
        "      print(f\"\\nStarting run {i+1} of {max_runs}\\n\")\n",
        "    # trim to get 90% subset\n",
        "    V_trimmed, Y_trimmed, V_hat_trimmed = make_stratified_subset(V, Y_hat, V_hat)\n",
        "\n",
        "    # Initialisation\n",
        "    if config[\"rank\"] == \"auto\":\n",
        "      rank = len(set(Y_trimmed))\n",
        "    elif isinstance(config[\"rank\"], int):\n",
        "      rank = config[\"rank\"]\n",
        "    else:\n",
        "      raise ValueError(f\"Error! config rank must be an integer or auto. It is currently {config['rank']}\")\n",
        "\n",
        "    # randomly initialise the values of W and H\n",
        "    W_0 = rng.random((V_trimmed.shape[0], rank))\n",
        "    H_0 = rng.random((rank, V_trimmed.shape[1]))\n",
        "\n",
        "    # call the NMF algorithm and output the RRE (dependant on which NMF algorithm)\n",
        "    start = time.time()\n",
        "\n",
        "    if config[\"nmf_type\"] == \"Frobenius\":\n",
        "      W, H, errors = fse_mur(V_trimmed, W_0, H_0, max_iterations=config[\"max_iterations\"], verbosity=verbosity)\n",
        "      end = time.time()\n",
        "      RRE = rre_fse(V_hat_trimmed, W, H)\n",
        "      if verbosity >= 1:\n",
        "        print(f\"FSE RRE = {RRE:.6f}\")\n",
        "\n",
        "    elif config[\"nmf_type\"] == \"L21\":\n",
        "      W, H, errors = l21_norm_mur(V_trimmed, W_0, H_0, max_iterations=config[\"max_iterations\"], verbosity=verbosity)\n",
        "      end = time.time()\n",
        "      RRE = rre_l21_norm(V_hat_trimmed, W, H)\n",
        "      if verbosity >= 1:\n",
        "        print(f\"L2,1 Norm RRE = {RRE:.6f}\")\n",
        "    else:\n",
        "      raise ValueError(f\"Unkown NMF type selected in config: {config['nmf_type']}\")\n",
        "      exit(1)\n",
        "\n",
        "    if verbosity >= 1:\n",
        "      print(f\"Training completed in {end - start:.2f} seconds\")\n",
        "\n",
        "    rre_scores.append(RRE)\n",
        "\n",
        "    # Assign cluster labels.\n",
        "    Y_pred = assign_cluster_label(H.T, Y_trimmed, verbosity=verbosity)\n",
        "\n",
        "    acc = accuracy_score(Y_trimmed, Y_pred)\n",
        "    nmi = normalized_mutual_info_score(Y_trimmed, Y_pred)\n",
        "    if verbosity >= 1:\n",
        "      print(f\"Acc: {acc:.4f} NMI: {nmi:.4f}\")\n",
        "\n",
        "    acc_scores.append(acc)\n",
        "    nmi_scores.append(nmi)\n",
        "\n",
        "\n",
        "  # final results, output the mean and stdev for each of the three metrics\n",
        "  print(f\"\\nRRE mean: {np.mean(rre_scores):.4f} std: {np.std(rre_scores):.4f}\")\n",
        "  print(f\"ACC mean: {np.mean(acc_scores):.4f} std: {np.std(acc_scores):.4f}\")\n",
        "  print(f\"NMI mean: {np.mean(nmi_scores):.4f} std: {np.std(nmi_scores):.4f}\")\n",
        "\n",
        "\n",
        "  print(\"\\n------------------------------------------\\n\")\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T0NvjK7toSDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configs = [\n",
        "    {\n",
        "    \"dataset\": \"ORL\",             # \"ORL\" or \"YALE\"\n",
        "    \"normalization\": \"per_image\",  # \"none\" or \"per_image\" or \"global\"\n",
        "    \"noise_p\": 0.2,\n",
        "    \"noise_r\": 0.1,\n",
        "    \"nmf_type\": \"Frobenius\",            # \"Frobenius\" or \"L21\"\n",
        "    \"rank\": \"auto\",               # shared dimension between W and H. Set as an int or as \"auto\" to be num of classes in Y\n",
        "    \"max_iterations\": 10000,\n",
        "    \"tol\": 1e-5,                  # Tolerance, allows for early stopping\n",
        "    \"seed\": 0,                    # the seeding for RNG. Allows consistent replication\n",
        "    \"reduce_ORL\": 2,              # Reduction factor. ORL pics are smaller so maybe reduce less\n",
        "    \"reduce_YALE\": 3,             # YALE pics are larger so can reduce more\n",
        "    \"epsilon\": 1e-12\n",
        "},\n",
        "    {\n",
        "    \"dataset\": \"ORL\",             # \"ORL\" or \"YALE\"\n",
        "    \"normalization\": \"per_image\",  # \"none\" or \"per_image\" or \"global\"\n",
        "    \"noise_p\": 0.2,\n",
        "    \"noise_r\": 0.1,\n",
        "    \"nmf_type\": \"L21\",            # \"Frobenius\" or \"L21\"\n",
        "    \"rank\": \"auto\",               # shared dimension between W and H. Set as an int or as \"auto\" to be num of classes in Y\n",
        "    \"max_iterations\": 10000,\n",
        "    \"tol\": 1e-5,                  # Tolerance, allows for early stopping\n",
        "    \"seed\": 0,                    # the seeding for RNG. Allows consistent replication\n",
        "    \"reduce_ORL\": 2,              # Reduction factor. ORL pics are smaller so maybe reduce less\n",
        "    \"reduce_YALE\": 3,             # YALE pics are larger so can reduce more\n",
        "    \"epsilon\": 1e-12\n",
        "},\n",
        "    {\n",
        "    \"dataset\": \"ORL\",             # \"ORL\" or \"YALE\"\n",
        "    \"normalization\": \"per_image\",  # \"none\" or \"per_image\" or \"global\"\n",
        "    \"noise_p\": 0.3,\n",
        "    \"noise_r\": 0.4,\n",
        "    \"nmf_type\": \"Frobenius\",            # \"Frobenius\" or \"L21\"\n",
        "    \"rank\": \"auto\",               # shared dimension between W and H. Set as an int or as \"auto\" to be num of classes in Y\n",
        "    \"max_iterations\": 10000,\n",
        "    \"tol\": 1e-5,                  # Tolerance, allows for early stopping\n",
        "    \"seed\": 0,                    # the seeding for RNG. Allows consistent replication\n",
        "    \"reduce_ORL\": 2,              # Reduction factor. ORL pics are smaller so maybe reduce less\n",
        "    \"reduce_YALE\": 3,             # YALE pics are larger so can reduce more\n",
        "    \"epsilon\": 1e-12\n",
        "},\n",
        "]\n",
        "\n",
        "for i in range(len(configs)):\n",
        "    print(f\"Starting config {i+1} of {len(configs)}\\n\")\n",
        "    run_config(config, verbosity=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCnnAf4G7zkg",
        "outputId": "9e482bc6-29c8-4d63-fc4f-5378708f3d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting config 1 of 3\n",
            "\n",
            "dataset: ORL\n",
            "normalization: per_image\n",
            "noise_p: 0.3\n",
            "noise_r: 0.4\n",
            "nmf_type: Frobenius\n",
            "rank: auto\n",
            "max_iterations: 10000\n",
            "tol: 1e-05\n",
            "seed: 0\n",
            "reduce_ORL: 2\n",
            "reduce_YALE: 3\n",
            "epsilon: 1e-12\n",
            "\n",
            "RRE mean: 0.2977 std: 0.0004\n",
            "ACC mean: 0.5117 std: 0.0185\n",
            "NMI mean: 0.6833 std: 0.0049\n",
            "\n",
            "Starting config 2 of 3\n",
            "\n",
            "dataset: ORL\n",
            "normalization: per_image\n",
            "noise_p: 0.3\n",
            "noise_r: 0.4\n",
            "nmf_type: Frobenius\n",
            "rank: auto\n",
            "max_iterations: 10000\n",
            "tol: 1e-05\n",
            "seed: 0\n",
            "reduce_ORL: 2\n",
            "reduce_YALE: 3\n",
            "epsilon: 1e-12\n",
            "\n",
            "RRE mean: 0.2984 std: 0.0005\n",
            "ACC mean: 0.5372 std: 0.0263\n",
            "NMI mean: 0.6976 std: 0.0155\n",
            "\n",
            "Starting config 3 of 3\n",
            "\n",
            "dataset: ORL\n",
            "normalization: per_image\n",
            "noise_p: 0.3\n",
            "noise_r: 0.4\n",
            "nmf_type: Frobenius\n",
            "rank: auto\n",
            "max_iterations: 10000\n",
            "tol: 1e-05\n",
            "seed: 0\n",
            "reduce_ORL: 2\n",
            "reduce_YALE: 3\n",
            "epsilon: 1e-12\n",
            "\n",
            "RRE mean: 0.2971 std: 0.0003\n",
            "ACC mean: 0.5256 std: 0.0261\n",
            "NMI mean: 0.6891 std: 0.0164\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}